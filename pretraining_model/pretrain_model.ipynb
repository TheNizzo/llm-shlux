{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining model\n",
    "Our model right now generates random tokens. We need to pretrain it on a corpus of text. Lets's take the model we built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from gpt_model.model import GPT\n",
    "import torch\n",
    "\n",
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"n_embd\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"context_length\": 256\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPT(GPT_CONFIG)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, input_tensor, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    idx = input_tensor\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every efforte moves you IonATURES shortcomingsruction embarkedReward basemanodonselling credential\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_tokens(text, tokenizer):\n",
    "    encoding = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoding_tensor = torch.tensor(encoding).unsqueeze(0)\n",
    "    return encoding_tensor\n",
    "\n",
    "def tokens_to_text(tokens, tokenizer):\n",
    "    text = tokenizer.decode(tokens.squeeze(0).tolist())\n",
    "    return text\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Every efforte moves you\"\n",
    "token_ids = generate_text_simple(model, text_to_tokens(text, tokenizer), max_new_tokens=10, context_size=GPT_CONFIG[\"context_length\"])\n",
    "\n",
    "print(tokens_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train the model on a corpus of text. We'll use the 1984 book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a bright cold day in April, and the clocks were striking thirteen.\n",
      "Winston Smith, his chin n\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/1984.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters:  273973\n",
      "Total tokens:  66254\n"
     ]
    }
   ],
   "source": [
    "print(\"Total characters: \", len(text))\n",
    "total_tokens = len(tokenizer.encode(text))\n",
    "print(\"Total tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text))\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG[\"context_length\"],\n",
    "    stride=GPT_CONFIG[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG[\"context_length\"],\n",
    "    stride=GPT_CONFIG[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a loss function to train the model. We'll use the cross-entropy loss. It calculates the loss between the predicted probabilities and the true probabilities of the next token. Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(input, target, model, device):\n",
    "    input_tensor = input.to(device)\n",
    "    target_tensor = target.to(device)\n",
    "    logits = model(input_tensor)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_tensor.flatten())\n",
    "    return loss\n",
    "\n",
    "def compute_loader_loss(dataloader, model, device, num_batches=None):\n",
    "    val_loss = 0.0\n",
    "    if len(dataloader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "    for i, (input, target) in enumerate(dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = compute_loss(input, target, model, device)\n",
    "        val_loss += loss.item()\n",
    "    return val_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.9920, Validation loss: 10.9980\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = compute_loader_loss(train_loader, model, device)\n",
    "    val_loss = compute_loader_loss(val_loader, model, device)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to compute the loss on the training and validation sets. We can use this to monitor the performance of the model during training.\n",
    "\n",
    "We can now train the model.\n",
    "\n",
    "Let's implement the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = compute_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = compute_loader_loss(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = compute_loader_loss(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_tokens(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, input_tensor=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = tokens_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.896, Val loss 9.853\n",
      "Ep 1 (Step 000005): Train loss 8.438, Val loss 8.388\n",
      "Ep 1 (Step 000010): Train loss 7.358, Val loss 7.571\n",
      "Ep 1 (Step 000015): Train loss 7.222, Val loss 7.275\n",
      "Ep 1 (Step 000020): Train loss 7.119, Val loss 7.212\n",
      "Ep 1 (Step 000025): Train loss 7.042, Val loss 7.154\n",
      "Ep 1 (Step 000030): Train loss 6.992, Val loss 7.042\n",
      "Ep 1 (Step 000035): Train loss 6.917, Val loss 6.954\n",
      "Ep 1 (Step 000040): Train loss 6.968, Val loss 6.910\n",
      "Ep 1 (Step 000045): Train loss 6.719, Val loss 6.815\n",
      "Ep 1 (Step 000050): Train loss 6.724, Val loss 6.792\n",
      "Ep 1 (Step 000055): Train loss 6.661, Val loss 6.699\n",
      "Ep 1 (Step 000060): Train loss 6.397, Val loss 6.650\n",
      "Ep 1 (Step 000065): Train loss 6.536, Val loss 6.589\n",
      "Ep 1 (Step 000070): Train loss 6.427, Val loss 6.571\n",
      "Ep 1 (Step 000075): Train loss 6.178, Val loss 6.525\n",
      "Ep 1 (Step 000080): Train loss 6.328, Val loss 6.471\n",
      "Ep 1 (Step 000085): Train loss 6.021, Val loss 6.459\n",
      "Ep 1 (Step 000090): Train loss 6.235, Val loss 6.413\n",
      "Ep 1 (Step 000095): Train loss 6.077, Val loss 6.392\n",
      "Ep 1 (Step 000100): Train loss 6.022, Val loss 6.367\n",
      "Ep 1 (Step 000105): Train loss 6.093, Val loss 6.345\n",
      "Ep 1 (Step 000110): Train loss 5.954, Val loss 6.380\n",
      "Ep 1 (Step 000115): Train loss 6.067, Val loss 6.342\n",
      "Every effort moves you.                                                 \n",
      "Ep 2 (Step 000120): Train loss 5.982, Val loss 6.365\n",
      "Ep 2 (Step 000125): Train loss 5.886, Val loss 6.355\n",
      "Ep 2 (Step 000130): Train loss 5.916, Val loss 6.344\n",
      "Ep 2 (Step 000135): Train loss 5.994, Val loss 6.309\n",
      "Ep 2 (Step 000140): Train loss 5.760, Val loss 6.305\n",
      "Ep 2 (Step 000145): Train loss 5.876, Val loss 6.299\n",
      "Ep 2 (Step 000150): Train loss 5.906, Val loss 6.259\n",
      "Ep 2 (Step 000155): Train loss 5.607, Val loss 6.240\n",
      "Ep 2 (Step 000160): Train loss 5.803, Val loss 6.252\n",
      "Ep 2 (Step 000165): Train loss 5.717, Val loss 6.235\n",
      "Ep 2 (Step 000170): Train loss 5.605, Val loss 6.224\n",
      "Ep 2 (Step 000175): Train loss 5.664, Val loss 6.214\n",
      "Ep 2 (Step 000180): Train loss 5.792, Val loss 6.187\n",
      "Ep 2 (Step 000185): Train loss 5.736, Val loss 6.174\n",
      "Ep 2 (Step 000190): Train loss 5.645, Val loss 6.182\n",
      "Ep 2 (Step 000195): Train loss 5.671, Val loss 6.172\n",
      "Ep 2 (Step 000200): Train loss 5.543, Val loss 6.162\n",
      "Ep 2 (Step 000205): Train loss 5.405, Val loss 6.169\n",
      "Ep 2 (Step 000210): Train loss 5.404, Val loss 6.159\n",
      "Ep 2 (Step 000215): Train loss 5.379, Val loss 6.146\n",
      "Ep 2 (Step 000220): Train loss 5.506, Val loss 6.143\n",
      "Ep 2 (Step 000225): Train loss 5.401, Val loss 6.120\n",
      "Ep 2 (Step 000230): Train loss 5.500, Val loss 6.106\n",
      "Every effort moves you.                'I was a    'I got to the 'I    'I got to the  'I know, and \n",
      "Ep 3 (Step 000235): Train loss 5.314, Val loss 6.084\n",
      "Ep 3 (Step 000240): Train loss 5.399, Val loss 6.083\n",
      "Ep 3 (Step 000245): Train loss 5.373, Val loss 6.073\n",
      "Ep 3 (Step 000250): Train loss 5.402, Val loss 6.093\n",
      "Ep 3 (Step 000255): Train loss 5.349, Val loss 6.071\n",
      "Ep 3 (Step 000260): Train loss 5.345, Val loss 6.088\n",
      "Ep 3 (Step 000265): Train loss 5.421, Val loss 6.090\n",
      "Ep 3 (Step 000270): Train loss 5.180, Val loss 6.068\n",
      "Ep 3 (Step 000275): Train loss 5.371, Val loss 6.037\n",
      "Ep 3 (Step 000280): Train loss 5.353, Val loss 6.078\n",
      "Ep 3 (Step 000285): Train loss 5.348, Val loss 6.055\n",
      "Ep 3 (Step 000290): Train loss 5.142, Val loss 6.054\n",
      "Ep 3 (Step 000295): Train loss 5.140, Val loss 6.027\n",
      "Ep 3 (Step 000300): Train loss 5.279, Val loss 6.051\n",
      "Ep 3 (Step 000305): Train loss 5.128, Val loss 6.092\n",
      "Ep 3 (Step 000310): Train loss 5.091, Val loss 6.076\n",
      "Ep 3 (Step 000315): Train loss 5.007, Val loss 6.057\n",
      "Ep 3 (Step 000320): Train loss 5.187, Val loss 6.082\n",
      "Ep 3 (Step 000325): Train loss 5.104, Val loss 6.035\n",
      "Ep 3 (Step 000330): Train loss 5.099, Val loss 6.024\n",
      "Ep 3 (Step 000335): Train loss 5.003, Val loss 6.035\n",
      "Ep 3 (Step 000340): Train loss 4.864, Val loss 5.994\n",
      "Ep 3 (Step 000345): Train loss 5.049, Val loss 5.964\n",
      "Every effort moves you had been                 'Brien.                            \n",
      "Ep 4 (Step 000350): Train loss 4.936, Val loss 6.014\n",
      "Ep 4 (Step 000355): Train loss 4.960, Val loss 6.048\n",
      "Ep 4 (Step 000360): Train loss 4.878, Val loss 6.072\n",
      "Ep 4 (Step 000365): Train loss 4.874, Val loss 6.058\n",
      "Ep 4 (Step 000370): Train loss 4.888, Val loss 6.052\n",
      "Ep 4 (Step 000375): Train loss 4.722, Val loss 6.047\n",
      "Ep 4 (Step 000380): Train loss 4.768, Val loss 6.058\n",
      "Ep 4 (Step 000385): Train loss 4.768, Val loss 6.039\n",
      "Ep 4 (Step 000390): Train loss 4.832, Val loss 6.066\n",
      "Ep 4 (Step 000395): Train loss 4.492, Val loss 6.046\n",
      "Ep 4 (Step 000400): Train loss 4.711, Val loss 6.021\n",
      "Ep 4 (Step 000405): Train loss 4.597, Val loss 6.027\n",
      "Ep 4 (Step 000410): Train loss 4.821, Val loss 6.083\n",
      "Ep 4 (Step 000415): Train loss 4.506, Val loss 6.035\n",
      "Ep 4 (Step 000420): Train loss 4.678, Val loss 6.069\n",
      "Ep 4 (Step 000425): Train loss 4.655, Val loss 6.016\n",
      "Ep 4 (Step 000430): Train loss 4.661, Val loss 6.025\n",
      "Ep 4 (Step 000435): Train loss 4.606, Val loss 6.017\n",
      "Ep 4 (Step 000440): Train loss 4.222, Val loss 6.016\n",
      "Ep 4 (Step 000445): Train loss 4.658, Val loss 5.998\n",
      "Ep 4 (Step 000450): Train loss 4.548, Val loss 6.005\n",
      "Ep 4 (Step 000455): Train loss 4.465, Val loss 6.009\n",
      "Ep 4 (Step 000460): Train loss 4.503, Val loss 6.008\n",
      "Every effort moves you could not  'I think you,' said.        'I think you're a sort of a sort of course you to say to the 'I  ' 'I think you 'I\n",
      "Ep 5 (Step 000465): Train loss 4.312, Val loss 5.984\n",
      "Ep 5 (Step 000470): Train loss 4.115, Val loss 6.048\n",
      "Ep 5 (Step 000475): Train loss 4.166, Val loss 6.027\n",
      "Ep 5 (Step 000480): Train loss 4.395, Val loss 6.078\n",
      "Ep 5 (Step 000485): Train loss 4.414, Val loss 6.076\n",
      "Ep 5 (Step 000490): Train loss 4.196, Val loss 6.077\n",
      "Ep 5 (Step 000495): Train loss 4.116, Val loss 6.087\n",
      "Ep 5 (Step 000500): Train loss 4.135, Val loss 6.069\n",
      "Ep 5 (Step 000505): Train loss 4.268, Val loss 6.113\n",
      "Ep 5 (Step 000510): Train loss 3.780, Val loss 6.075\n",
      "Ep 5 (Step 000515): Train loss 4.016, Val loss 6.087\n",
      "Ep 5 (Step 000520): Train loss 3.843, Val loss 6.078\n",
      "Ep 5 (Step 000525): Train loss 3.919, Val loss 6.055\n",
      "Ep 5 (Step 000530): Train loss 3.786, Val loss 6.072\n",
      "Ep 5 (Step 000535): Train loss 3.881, Val loss 6.100\n",
      "Ep 5 (Step 000540): Train loss 3.667, Val loss 6.106\n",
      "Ep 5 (Step 000545): Train loss 3.937, Val loss 6.051\n",
      "Ep 5 (Step 000550): Train loss 4.023, Val loss 6.075\n",
      "Ep 5 (Step 000555): Train loss 3.743, Val loss 6.102\n",
      "Ep 5 (Step 000560): Train loss 3.652, Val loss 6.040\n",
      "Ep 5 (Step 000565): Train loss 3.656, Val loss 6.079\n",
      "Ep 5 (Step 000570): Train loss 3.622, Val loss 6.077\n",
      "Ep 5 (Step 000575): Train loss 3.726, Val loss 6.060\n",
      "Every effort moves you, and  to be able to the Party, and the end of the  to be able to the of course, and to the Party, and of course, and  was not of the words, and \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = GPT(GPT_CONFIG)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
